{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "### synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_print_elapsed_time' from 'sklearn.utils' (/Users/pengjiabeitang/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msksurv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concordance_index_censored\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_curve\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 数据加载和预处理\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# data = pd.read_csv('synthetic_data.csv', index_col=0)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleaned_Data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/__init__.py:53\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combine\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ensemble\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptions\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/ensemble/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`imblearn.ensemble` module include methods generating\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03munder-sampled subsets combined inside an ensemble.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_easy_ensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EasyEnsembleClassifier\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bagging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BalancedBaggingClassifier\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_forest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BalancedRandomForestClassifier\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/ensemble/_easy_ensemble.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _random_state_docstring\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _deprecate_positional_args\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[1;32m     23\u001b[0m MAX_INT \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax\n\u001b[1;32m     26\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\n\u001b[1;32m     27\u001b[0m     sampling_strategy\u001b[38;5;241m=\u001b[39mBaseUnderSampler\u001b[38;5;241m.\u001b[39m_sampling_strategy_docstring,\n\u001b[1;32m     28\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m_n_jobs_docstring,\n\u001b[1;32m     29\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m_random_state_docstring,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEasyEnsembleClassifier\u001b[39;00m(BaggingClassifier):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/pipeline.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _print_elapsed_time\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetaestimators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m if_delegate_has_method\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_memory\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_print_elapsed_time' from 'sklearn.utils' (/Users/pengjiabeitang/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.metrics import roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 数据加载和预处理\n",
    "data = pd.read_csv('synthetic_data.csv', index_col=0)\n",
    "\n",
    "le = LabelEncoder()\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_columns:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "X = data.drop(['Label', 'Employee code/number'], axis=1)\n",
    "y = data['Label']\n",
    "time = data['Years in current role']\n",
    "\n",
    "# 修改标签为1年内是否离职\n",
    "y_1year = (time <= 1) & y\n",
    "\n",
    "y_surv = np.array([(bool(y_i), min(t_i, 1.0)) for y_i, t_i in zip(y, time)], \n",
    "                  dtype=[('Label', bool), ('time', float)])\n",
    "\n",
    "# 分割数据\n",
    "X_train, X_test, y_train, y_test, y_surv_train, y_surv_test = train_test_split(\n",
    "    X, y_1year, y_surv, test_size=0.2, random_state=42)\n",
    "\n",
    "# 特征选择 (仅在训练集上进行)\n",
    "selector = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), threshold='median')\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# 获取被选中的特征名称\n",
    "selected_feature_names = X.columns[selector.get_support()].tolist()\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# 处理类别不平衡\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 重新创建生存数据\n",
    "y_surv_train_resampled = np.array([(bool(y_i), 1.0 if y_i else 0.0) for y_i in y_train_resampled], \n",
    "                                  dtype=[('Label', bool), ('time', float)])\n",
    "\n",
    "# 训练RSF模型\n",
    "rsf = RandomSurvivalForest(n_estimators=50, max_depth=5, min_samples_leaf=10, random_state=42)\n",
    "rsf.fit(X_train_resampled, y_surv_train_resampled)\n",
    "\n",
    "# 预测1年生存概率\n",
    "def predict_1year_survival(rsf, X):\n",
    "    surv_funcs = rsf.predict_survival_function(X)\n",
    "    surv_probs_1year = [sf(1.0) for sf in surv_funcs]\n",
    "    return np.array(surv_probs_1year)\n",
    "\n",
    "surv_prob_train_1year = predict_1year_survival(rsf, X_train_resampled)\n",
    "surv_prob_test_1year = predict_1year_survival(rsf, X_test_scaled)\n",
    "\n",
    "# 将1年生存概率添加到特征中\n",
    "X_train_with_surv = np.column_stack((X_train_resampled, surv_prob_train_1year))\n",
    "X_test_with_surv = np.column_stack((X_test_scaled, surv_prob_test_1year))\n",
    "\n",
    "\n",
    "# 训练RF分类器\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=5, min_samples_leaf=10, random_state=42)\n",
    "\n",
    "# 使用分层交叉验证\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(rf, X_train_with_surv, y_train_resampled, cv=cv)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(f\"Mean CV score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# 在整个训练集上训练最终模型\n",
    "rf.fit(X_train_with_surv, y_train_resampled)\n",
    "\n",
    "# 在测试集上评估\n",
    "y_pred = rf.predict(X_test_with_surv)\n",
    "y_pred_proba = rf.predict_proba(X_test_with_surv)[:, 1]\n",
    "\n",
    "print(\"\\n随机森林分类器评估（1年内离职预测）：\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_pred_proba))\n",
    "print(\"Average Precision Score:\", average_precision_score(y_test, y_pred_proba))\n",
    "print(\"\\n分类报告:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 绘制PR曲线\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()\n",
    "\n",
    "# 计算最佳阈值\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"\\n最佳阈值: {optimal_threshold:.4f}\")\n",
    "\n",
    "# 使用新阈值进行预测\n",
    "y_pred_new = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "print(\"\\n使用最佳阈值的随机森林分类器评估（1年内离职预测）：\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_new))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_pred_proba))\n",
    "print(\"\\n分类报告:\")\n",
    "print(classification_report(y_test, y_pred_new))\n",
    "\n",
    "# 评估随机生存森林\n",
    "c_index = concordance_index_censored(y_surv_test['Label'], y_surv_test['time'], -rsf.predict(X_test_scaled))\n",
    "print(\"\\n随机生存森林评估：\")\n",
    "print(f\"C-index: {c_index[0]:.4f}\")\n",
    "\n",
    "# 特征重要性分析\n",
    "feature_importance = rf.feature_importances_\n",
    "feature_names = selected_feature_names + ['Survival Probability']\n",
    "for name, importance in zip(feature_names, feature_importance):\n",
    "    print(f\"{name}: {importance:.4f}\")\n",
    "\n",
    "# 学习曲线分析\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    rf, X_train_with_surv, y_train_resampled, cv=5,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training score')\n",
    "plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Cross-validation score')\n",
    "plt.xlabel('Training examples')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 创建结果数据框\n",
    "results = pd.DataFrame({\n",
    "    'Predicted_Label': y_pred_new,\n",
    "    'Turnover_Probability_1Year': y_pred_proba\n",
    "})\n",
    "\n",
    "# 添加原始特征\n",
    "for i, name in enumerate(selected_feature_names):\n",
    "    results[name] = X_test_selected[:, i]\n",
    "\n",
    "# 为host提供建议\n",
    "def provide_recommendation(prob, threshold):\n",
    "    if prob > threshold * 1.5:  # 高于阈值50%\n",
    "        return f\"High risk: There is a {prob:.1%} probability that this employee will leave within the next year. It is recommended to take retention measures immediately.\"\n",
    "    elif prob >= threshold:\n",
    "        return f\"Medium risk: The employee has a {prob:.1%} probability of leaving within the next year. It is recommended to closely monitor and consider taking preventive measures.\"\n",
    "    else:\n",
    "        return f\"Low risk: This employee has a {prob:.1%} probability of leaving within the next year. Currently, the risk is low, but regular monitoring is still necessary.\"\n",
    "\n",
    "# 为每个员工生成建议\n",
    "results['Recommendation'] = results.apply(lambda row: provide_recommendation(row['Turnover_Probability_1Year'], optimal_threshold), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n部分预测结果:\")\n",
    "# print(results.head(10))\n",
    "\n",
    "# # 分析预测的生存时间分布\n",
    "# print(\"\\n预测生存时间的统计信息：\")\n",
    "# print(results['Turnover_Probability_1Year'].describe())\n",
    "\n",
    "# 显示所有 Predicted_Label 为 1 的行\n",
    "print(\"\\n所有预测为离职的员工：\")\n",
    "predicted_turnover = results[results['Predicted_Label'] == 1]\n",
    "print(predicted_turnover[['Predicted_Label', 'Turnover_Probability_1Year', 'Recommendation']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征重要性分析\n",
    "feature_importance = rf.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': selected_feature_names + ['Survival Probability'],\n",
    "    'importance': feature_importance\n",
    "})\n",
    "importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "print(\"\\n特征重要性：\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kaggle data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.metrics import roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 数据加载和预处理\n",
    "data = pd.read_csv('Cleaned_Data.csv', index_col=0)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_columns:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "X = data.drop(['Label'], axis=1)\n",
    "y = data['Label']\n",
    "time = data['YearsAtCompany']\n",
    "\n",
    "# 修改标签为1年内是否离职\n",
    "y_1year = (time <= 1) & y\n",
    "\n",
    "y_surv = np.array([(bool(y_i), min(t_i, 1.0)) for y_i, t_i in zip(y, time)], \n",
    "                  dtype=[('Label', bool), ('time', float)])\n",
    "\n",
    "# 分割数据\n",
    "X_train, X_test, y_train, y_test, y_surv_train, y_surv_test = train_test_split(\n",
    "    X, y_1year, y_surv, test_size=0.2, random_state=42)\n",
    "\n",
    "# 特征选择 (仅在训练集上进行)\n",
    "selector = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), threshold='median')\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# 获取被选中的特征名称\n",
    "selected_feature_names = X.columns[selector.get_support()].tolist()\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# 处理类别不平衡\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 重新创建生存数据\n",
    "y_surv_train_resampled = np.array([(bool(y_i), 1.0 if y_i else 0.0) for y_i in y_train_resampled], \n",
    "                                  dtype=[('Label', bool), ('time', float)])\n",
    "\n",
    "# 训练RSF模型\n",
    "rsf = RandomSurvivalForest(n_estimators=50, max_depth=5, min_samples_leaf=10, random_state=42)\n",
    "rsf.fit(X_train_resampled, y_surv_train_resampled)\n",
    "\n",
    "# 预测1年生存概率\n",
    "def predict_1year_survival(rsf, X):\n",
    "    surv_funcs = rsf.predict_survival_function(X)\n",
    "    surv_probs_1year = [sf(1.0) for sf in surv_funcs]\n",
    "    return np.array(surv_probs_1year)\n",
    "\n",
    "surv_prob_train_1year = predict_1year_survival(rsf, X_train_resampled)\n",
    "surv_prob_test_1year = predict_1year_survival(rsf, X_test_scaled)\n",
    "\n",
    "# 将1年生存概率添加到特征中\n",
    "X_train_with_surv = np.column_stack((X_train_resampled, surv_prob_train_1year))\n",
    "X_test_with_surv = np.column_stack((X_test_scaled, surv_prob_test_1year))\n",
    "\n",
    "\n",
    "# 训练RF分类器\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=5, min_samples_leaf=10, random_state=42)\n",
    "\n",
    "# 使用分层交叉验证\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(rf, X_train_with_surv, y_train_resampled, cv=cv)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(f\"Mean CV score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# 在整个训练集上训练最终模型\n",
    "rf.fit(X_train_with_surv, y_train_resampled)\n",
    "\n",
    "# 在测试集上评估\n",
    "y_pred = rf.predict(X_test_with_surv)\n",
    "y_pred_proba = rf.predict_proba(X_test_with_surv)[:, 1]\n",
    "\n",
    "print(\"\\n随机森林分类器评估（1年内离职预测）：\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_pred_proba))\n",
    "print(\"Average Precision Score:\", average_precision_score(y_test, y_pred_proba))\n",
    "print(\"\\n分类报告:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 计算最佳阈值\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"\\n最佳阈值: {optimal_threshold:.4f}\")\n",
    "\n",
    "# 使用新阈值进行预测\n",
    "y_pred_new = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "print(\"\\n使用最佳阈值的随机森林分类器评估（1年内离职预测）：\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_new))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_pred_proba))\n",
    "print(\"\\n分类报告:\")\n",
    "print(classification_report(y_test, y_pred_new))\n",
    "\n",
    "# 评估随机生存森林\n",
    "c_index = concordance_index_censored(y_surv_test['Label'], y_surv_test['time'], -rsf.predict(X_test_scaled))\n",
    "print(\"\\n随机生存森林评估：\")\n",
    "print(f\"C-index: {c_index[0]:.4f}\")\n",
    "\n",
    "# 特征重要性分析\n",
    "feature_importance = rf.feature_importances_\n",
    "feature_names = selected_feature_names + ['Survival Probability']\n",
    "for name, importance in zip(feature_names, feature_importance):\n",
    "    print(f\"{name}: {importance:.4f}\")\n",
    "\n",
    "# # 学习曲线分析\n",
    "# train_sizes, train_scores, test_scores = learning_curve(\n",
    "#     rf, X_train_with_surv, y_train_resampled, cv=5,\n",
    "#     train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training score')\n",
    "# plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Cross-validation score')\n",
    "# plt.xlabel('Training examples')\n",
    "# plt.ylabel('Score')\n",
    "# plt.title('Learning Curve')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # 创建结果数据框\n",
    "# results = pd.DataFrame({\n",
    "#     'Predicted_Label': y_pred_new,\n",
    "#     'Turnover_Probability_1Year': y_pred_proba\n",
    "# })\n",
    "\n",
    "# # 添加原始特征\n",
    "# for i, name in enumerate(selected_feature_names):\n",
    "#     results[name] = X_test_selected[:, i]\n",
    "\n",
    "# # 为host提供建议\n",
    "# def provide_recommendation(prob, threshold):\n",
    "#     if prob > threshold * 1.5:  # 高于阈值50%\n",
    "#         return f\"High risk: There is a {prob:.1%} probability that this employee will leave within the next year. It is recommended to take retention measures immediately.\"\n",
    "#     elif prob >= threshold:\n",
    "#         return f\"Medium risk: The employee has a {prob:.1%} probability of leaving within the next year. It is recommended to closely monitor and consider taking preventive measures.\"\n",
    "#     else:\n",
    "#         return f\"Low risk: This employee has a {prob:.1%} probability of leaving within the next year. Currently, the risk is low, but regular monitoring is still necessary.\"\n",
    "\n",
    "# # 为每个员工生成建议\n",
    "# results['Recommendation'] = results.apply(lambda row: provide_recommendation(row['Turnover_Probability_1Year'], optimal_threshold), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存模型和相关对象\n",
    "joblib.dump(selector, 'RFRSFmodel/feature_selector.joblib')\n",
    "joblib.dump(scaler, 'RFRSFmodel/scaler.joblib')\n",
    "joblib.dump(rf, 'RFRSFmodel/random_forest_classifier.joblib')\n",
    "joblib.dump(rsf, 'RFRSFmodel/random_survival_forest.joblib')\n",
    "joblib.dump(le, 'RFRSFmodel/label_encoder.joblib')\n",
    "print(le.classes_)\n",
    "# 保存最佳阈值\n",
    "np.save('RFRSFmodel/optimal_threshold.npy', optimal_threshold)\n",
    "\n",
    "# 保存选中的特征名称\n",
    "with open('RFRSFmodel/selected_features.txt', 'w') as f:\n",
    "    for feature in selected_feature_names:\n",
    "        f.write(f\"{feature}\\n\")\n",
    "\n",
    "print(\"模型和相关对象已保存。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_employee_turnover(employee_data):\n",
    "    # 加载模型和相关对象\n",
    "    selector = joblib.load('RFRSFmodel/feature_selector.joblib')\n",
    "    scaler = joblib.load('RFRSFmodel/scaler.joblib')\n",
    "    rf = joblib.load('RFRSFmodel/random_forest_classifier.joblib')\n",
    "    rsf = joblib.load('RFRSFmodel/random_survival_forest.joblib')\n",
    "    optimal_threshold = np.load('RFRSFmodel/optimal_threshold.npy')\n",
    "    \n",
    "    # 读取选中的特征名称\n",
    "    with open('RFRSFmodel/selected_features.txt', 'r') as f:\n",
    "        selected_features = [line.strip() for line in f]\n",
    "    \n",
    "    # 加载 LabelEncoder\n",
    "    le = joblib.load('RFRSFmodel/label_encoder.joblib')\n",
    "    \n",
    "    print(\"Expected features:\", selected_features)\n",
    "    print(\"Actual features:\", employee_data.columns.tolist())\n",
    "    \n",
    "    # 只选择需要的特征\n",
    "    X = employee_data[selected_features].copy()\n",
    "    \n",
    "    # 对分类特征进行编码\n",
    "    categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_columns:\n",
    "        if col in selected_features:\n",
    "            if set(X[col].unique()) - set(le.classes_):\n",
    "                print(f\"Warning: New categories found in {col}. Treating them as the most frequent category.\")\n",
    "                X[col] = X[col].map(lambda x: x if x in le.classes_ else le.classes_[0])\n",
    "            X[col] = le.transform(X[col])\n",
    "    \n",
    "    # 标准化特征\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # 预测生存概率\n",
    "    surv_prob = rsf.predict(X_scaled)\n",
    "    \n",
    "    # 将生存概率添加到特征中\n",
    "    X_with_surv = np.column_stack((X_scaled, surv_prob))\n",
    "    \n",
    "    # 预测离职概率\n",
    "    turnover_prob = rf.predict_proba(X_with_surv)[:, 1]\n",
    "    \n",
    "    # 预测标签\n",
    "    predicted_label = (turnover_prob >= optimal_threshold).astype(int)\n",
    "    \n",
    "    # 估计生存时间\n",
    "    survival_times = estimate_survival_time(rsf, X_scaled)\n",
    "    \n",
    "    # 生成建议\n",
    "    recommendations = [provide_recommendation(prob, time, optimal_threshold) \n",
    "                       for prob, time in zip(turnover_prob, survival_times)]\n",
    "    \n",
    "    # 创建结果DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        'Predicted_Label': predicted_label,\n",
    "        'Turnover_Probability': turnover_prob,\n",
    "        'Estimated_Survival_Time': survival_times,\n",
    "        'Recommendation': recommendations\n",
    "    })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 读取数据\n",
    "# df = pd.read_csv('synthetic_data.csv', index_col=0)\n",
    "\n",
    "# # 分别选择label == 0 和 label == 1的25个样本\n",
    "# df_label_0 = df[df['Label'] == 0].sample(25, random_state=42)\n",
    "# df_label_1 = df[df['Label'] == 1].sample(25, random_state=42)\n",
    "\n",
    "# # 合并数据\n",
    "# df_test = pd.concat([df_label_0, df_label_1])\n",
    "\n",
    "# # 保存为新的CSV文件\n",
    "# df_test.to_csv('test_data.csv', index=False)\n",
    "# print(\"已成功导出50个样本到test_data.csv文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主脚本\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.metrics import roc_curve\n",
    "import joblib\n",
    "\n",
    "# 加载新的员工数据\n",
    "new_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# 读取选中的特征名称\n",
    "with open('RFRSFmodel/selected_features.txt', 'r') as f:\n",
    "    selected_features = [line.strip() for line in f]\n",
    "\n",
    "# 检查是否所有需要的特征都存在\n",
    "missing_features = set(selected_features) - set(new_data.columns)\n",
    "if missing_features:\n",
    "    raise ValueError(f\"The following features are missing in the test data: {missing_features}\")\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = predict_employee_turnover(new_data)\n",
    "\n",
    "# 打印结果\n",
    "print(predictions)\n",
    "\n",
    "# # 可选：保存结果到CSV文件\n",
    "# predictions.to_csv('employee_turnover_predictions.csv', index=False)\n",
    "# print(\"预测结果已保存到 'employee_turnover_predictions.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
